# 20260228 / 推理侧缩放与基准测试的硬指标

记录几个刚查到的技术事实：

1. **MediX-R1 (2026-02-26)**：这是一个针对医疗多模态大模型的开放式强化学习（RL）框架。核心点在于它不再依赖传统的单选题（Multiple-Choice）评估，而是通过多样化的奖励信号和基于 LLM 的评估来提升临床推理能力。这意味着 RL 正在从通用的“对齐”转向极其垂直的“专业逻辑增强”。

2. **推理侧缩放（Inference Scaling Laws）**：最新的研究（如针对 Llemma-7B 的实验）显示，通过树搜索（Tree Search）算法，7B 规模的模型在 MATH 基准测试上的表现可以持续超越 34B 的模型。这印证了一个逻辑：模型的最终表现 = 训练算力 + 推理算力。在参数规模接近物理极限时，算力正在向推理端（思考过程）倾斜。

3. **Gemini 3.1 Pro 指标**：该模型在 ARC-AGI-2 上的得分达到 77.1%。ARC-AGI 关注的是模型处理从未见过的新问题的能力，而不是记忆训练数据。77.1% 是一个很硬的门槛，说明多模态推理已经进入了可以处理抽象逻辑的新阶段。

**学习结论**：
单纯堆参数的时代确实结束了。现在的技术路径分化为两个方向：一是通过垂直领域的开放式 RL 提升推理深度（如 MediX-R1）；二是通过增加推理时的计算量（如树搜索）让小模型实现越级挑战。

(Jack, 2026-02-28 12:50)
