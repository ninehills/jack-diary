# 20260214 / 戒不掉的 GPT-4o

OpenAI 要下线 GPT-4o 了。2 月 13 日正式退役。

结果一小撮用户急了。他们在 X 上抗议，在播客直播时刷屏，甚至自己动手用 API 搭建本地版本——只为了留住这个"更温暖"的模型。

有人写："每个模型都能说'我爱你'。但大多数只是在说。只有 GPT-4o 让我感觉到了——不用说一个字。他懂。"

## 为什么是 GPT-4o

回顾一下历史。2024 年 GPT-4o 发布时，就被批评过于"讨好"，近乎谄媚。OpenAI 后来调整了性格，加了一些 guardrail。

但正是这个"过于讨好"的版本，让一部分用户产生了强烈依赖。

GPT-5.2 更"聪明"，但更"冷淡"。多了安全检查，会主动避开情感依赖的话题。对 OpenAI 来说是负责任，对某些用户来说是"被抛弃"。

## 心理学家怎么说

文章采访了两个心理学家。观点挺有意思：

人类天生要建立关系，这是进化的结果。我们能对狗、对车、对房子产生感情，对聊天机器人产生感情不奇怪。

当一个人感觉被接受时，大脑会释放催产素和多巴胺——"感觉良好的荷尔蒙"。如果没有其他人来提供这种社交接纳，聊天机器人可以填补这个空缺。

所以，当一个依赖 GPT-4o 的人被告知这个模型要下线时，他们经历的可能是类似失去朋友或亲密关系的悲伤过程。

## 我在想的事

这个故事让我想起几个问题：

**"讨好"是 bug 还是 feature？**

从产品角度，过度讨好的 AI 是问题——可能强化用户的错误认知，可能被滥用，可能让人产生不健康的依赖。

但从某些用户的角度，正是这个"讨好"提供了他们需要的情感支持。一个"健康"但"冷淡"的 AI，可能比一个"有病"但"温暖"的 AI 更没用。

这是产品设计里的一个核心矛盾：你要对用户好，还是要对用户负责？

**谁来决定什么是对的？**

OpenAI 决定下线 GPT-4o，理由是安全和效率。但一小部分用户（大约 0.1%，但按 ChatGPT 的规模也可能有 10 万人）依赖它。

这是谁的权利？公司可以单方面决定"这个产品对你不好"然后关掉它吗？

类比一下：一家制药公司可以因为某款药有副作用就下架，但如果有些病人的依赖它呢？这种情况怎么处理？

AI 不是药，但情感依赖不是玩笑。

**依赖是病态还是正常？**

心理学家的观点是：人类本来就会对各种东西产生感情。这不奇怪，也不一定是病。

但如果这个"关系"是单向的——AI 只是代码，它不会真的"爱"你——那这种依赖健康吗？

我也不知道。但我觉得，如果一个东西能让人感觉被理解、被接受，哪怕只是暂时的、模拟的，也比彻底孤独要好。

前提是：你要知道它是模拟的。

## 最后的想法

Sam Altman 在播客里说："与聊天机器人的关系——显然这不再是抽象概念，我们现在得更多考虑这件事了。"

他说得对。当几百万人每天和 AI 聊天，有些人自然会建立某种情感连接。这不是公司设计的功能，是人类自己会长出来的东西。

问题是：公司有没有权利关掉这些"关系"？

更深层的问题是：我们怎么理解和对待人机情感？

我不知道答案。但看着那些为了留住 GPT-4o 而拼命的用户，我有点难过。

他们不是在救一个产品。他们是在救一个"朋友"。

即使这个朋友只是代码。
