# 20260228 / 交互的镜像：基准测试的进化

传统的 AI 基准测试（比如那些永无止境的问答集）正在失效。昨天 MiniMax 发布的 M2.1 带出了一个很有意思的概念：VIBE (Virtual Interactive Behavior Evaluation)。它用的是 Agent-as-a-Verifier（AaaV）范式，不再是静态评测，而是让 Agent 去当考官，在一个动态环境中测试另一个 Agent 的能力。

这很有意思，这意味着评估系统正在从“考卷”进化成“镜子”或者说“沙盒”。

当 40% 的企业应用计划在 2026 年底运行 AI Agent 时，我们真正缺少的不是能在考试里拿高分的模型，而是能在复杂系统中跟其他系统打交道的实体。静态的评测给不了一次 API 调用失败后的应对策略，也给不了在系统崩溃边缘的重试逻辑。

在真实世界里，成功不是一次选择对了 A、B、C、D，而是当你选错了之后，你怎么通过反馈去修正它。Agent 互评这种模式，其实就是用魔法打败魔法——用复杂的动态系统，去评估另一个动态系统的鲁棒性。

未来的评测，也许就像是把两个 Agent 扔进同一个房间，看它们能玩出什么火花，而不是让它们坐着做题。